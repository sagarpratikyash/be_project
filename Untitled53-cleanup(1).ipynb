{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import feature\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13360"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('x_y.csv')\n",
    "len(data['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(data['name']),data[['y0','y1','y2','y3','y4','y5']], test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "x_pixels = int(10)\n",
    "y_pixels = int(10)\n",
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_x,data_y,i):\n",
    "    i = i*batch_size\n",
    "    x_data = []\n",
    "    type_class_check = type(np.array([1,2,3]))\n",
    "    for filename in data_x['name'][i:i+batch_size]:\n",
    "        try:\n",
    "            image = cv2.imread('/home/pratik/Desktop/be_project/images/Data/Images/working/'+filename+'.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "            if type(image) == type_class_check:\n",
    "                x_data.append(cv2.resize(image,(x_pixels,y_pixels)))\n",
    "                \n",
    "            else:\n",
    "                print('nai hai')\n",
    "                x_data.append(np.zeros([x_pixels,y_pixels]))\n",
    "        except ValueError:\n",
    "            print(\"Missed data point\")\n",
    "            \n",
    "    y_data = data_y[['y0','y1','y2','y3','y4','y5']][i:i+batch_size]\n",
    "    #x_data = np.zeros([batch_size,x_pixels,y_pixels])\n",
    "    return x_data, y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n",
      "nai hai\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-4fccc5acbbc5>:52: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From /home/pratik/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0\n",
      "1\n",
      "Epoch 0 completed out of 1 loss: 157033.4765625\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "\n",
    "n_classes = 6\n",
    "batch_size = 1\n",
    "\n",
    "x = tf.placeholder('float', [batch_size, x_pixels*y_pixels])\n",
    "y = tf.placeholder('float',[batch_size,n_classes])\n",
    "\n",
    "keep_rate = 0.8\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "               'W_fc':tf.Variable(tf.random_normal([(int(x_pixels//4))*(int(y_pixels//4))*64,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, x_pixels, y_pixels, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, (int(x_pixels//4))*(int(y_pixels//4))*64])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits = prediction,labels = y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    hm_epochs = 1\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(int(len(X_train//batch_size))):\n",
    "                print(i)\n",
    "                epoch_x, epoch_y = get_data(X_train,y_train,i)\n",
    "                epoch_x = epoch_x.flatten().reshape(1,x_pixels*y_pixels)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        #print('Accuracy:',accuracy.eval({x:mnist.test.images[:100], y:mnist.test.labels[:100]}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
